{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e96c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff3f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('extended_stoma_dataset.csv')\n",
    "\n",
    "data['end_year'] = data.dates.apply(lambda a: int(a.split('-')[1]))\n",
    "data['birth_year'] = data['date_of_birth'].apply(lambda a: int('20'+a.split('.')[-1] ))\n",
    "data['right_age'] = data[['end_year', 'birth_year']].apply(lambda a: a[0]-a[1], axis=1)\n",
    "data['kpu'] = data[['num_caries', 'num_filling_caries',\n",
    "                    'num_filling_no_caries',\n",
    "                    'num_removed_caused_by_caries', 'num_removed_other_reasons']].sum(axis=1)\n",
    "\n",
    "train = data.drop(data[data['dates'] == '2017-2018'].index, axis=0)\n",
    "test = data[data['dates'] == '2017-2018']\n",
    "\n",
    "NUM_FEATURES = [\n",
    "       'prosthesis crown veneer', 'sealed fissure', 'uncut tooth', 'fluorosis',\n",
    "               'sum_hygiene_index', 'right_age', ]\n",
    "LAST_FEATURES = [ 'not_registered', 'num_caries',\n",
    "       'num_filling_caries', 'num_filling_no_caries', 'num_healthy',\n",
    "       'num_removed_caused_by_caries', 'num_removed_other_reasons',] #признаки, участвующие в расчете целевой метрики, берем их только за последний год\n",
    "TARGET = ['kpu']\n",
    "CAT_FEATURES = ['nationality', 'place_of_birth',\n",
    "               'previous_place_of_living', 'bite_type', ]\n",
    "\n",
    "x_mean = train[NUM_FEATURES+['id']].groupby('id').mean()\n",
    "x_cat = train[CAT_FEATURES+['id']].groupby('id').agg(lambda x:x.value_counts().index[0])\n",
    "last_names = [c+' last' for c in NUM_FEATURES]\n",
    "x_last = pd.DataFrame(columns=[c+' last' for c in NUM_FEATURES])\n",
    "x_last[last_names] = train[NUM_FEATURES+['id']].groupby('id').last()\n",
    "\n",
    "last_cor_target_names = [c+' previous year' for c in LAST_FEATURES]\n",
    "x_prev_year = pd.DataFrame(columns=last_cor_target_names)\n",
    "x_prev_year = train[LAST_FEATURES+['id']].groupby('id').agg(lambda x: x.iloc[:len(x)-1].iloc[-1])\n",
    "\n",
    "x_past_target = train[TARGET+['id']].groupby('id').agg(lambda x: x.iloc[:len(x)-1].iloc[-1])\n",
    "x_past_target.columns = ['kpu_last']\n",
    "x_past_target['kpu'] = train[TARGET+['id']].groupby('id').agg(lambda x: x.iloc[-1])\n",
    "\n",
    "x_mean_test = data[NUM_FEATURES+['id']].groupby('id').mean()\n",
    "x_cat_test = data[CAT_FEATURES+['id']].groupby('id').agg(lambda x:x.value_counts().index[0])\n",
    "last_names = [c+' last' for c in NUM_FEATURES]\n",
    "x_last_test = pd.DataFrame(columns=[c+' last' for c in NUM_FEATURES])\n",
    "x_last_test[last_names] = data[NUM_FEATURES+['id']].groupby('id').last()\n",
    "\n",
    "last_cor_target_names = [c+' previous year' for c in LAST_FEATURES]\n",
    "x_prev_year_test = pd.DataFrame(columns=last_cor_target_names)\n",
    "x_prev_year_test = data[LAST_FEATURES+['id']].groupby('id').agg(lambda x: x.iloc[:len(x)-1].iloc[-1])\n",
    "\n",
    "x_past_target_test = data[TARGET+['id']].groupby('id').agg(lambda x: x.iloc[:len(x)-1].iloc[-1])\n",
    "x_past_target_test.columns = ['kpu_last']\n",
    "x_past_target_test['kpu'] = data[TARGET+['id']].groupby('id').agg(lambda x: x.iloc[-1])\n",
    "\n",
    "x_train = pd.concat([x_mean, x_cat, x_last,x_prev_year_test, x_past_target], axis=1)\n",
    "y_train = x_past_target['kpu']\n",
    "\n",
    "x_test = pd.concat([x_mean_test, x_cat_test, x_last_test, x_prev_year_test, x_past_target_test['kpu_last']], axis=1)\n",
    "x_test_with_kpu = pd.concat([x_mean_test, x_cat_test, x_last_test, x_prev_year_test, x_past_target_test], axis=1)\n",
    "# y_test = test['kpu']\n",
    "y_test = test[['id', 'kpu']].groupby('id').last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e9f05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-predictClass\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"agModels-predictClass/\"\n",
      "AutoGluon Version:  0.4.2\n",
      "Python Version:     3.8.10\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    191\n",
      "Train Data Columns: 24\n",
      "Label Column: kpu\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\tFirst 10 (of 16) unique label values:  [7, 6, 9, 2, 1, 8, 3, 4, 12, 5]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Updated label_count_threshold from 10 to 2 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 2 examples. AutoGluon will only keep 12 out of 16 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 2 examples that will be kept for training models: 0.9790575916230366\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    10974.09 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['prosthesis crown veneer', 'nationality', 'prosthesis crown veneer last', 'uncut tooth last']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  6 | ['sealed fissure', 'uncut tooth', 'fluorosis', 'sum_hygiene_index', 'right_age', ...]\n",
      "\t\t('int', [])    : 11 | ['sealed fissure last', 'fluorosis last', 'right_age last', 'not_registered', 'num_caries', ...]\n",
      "\t\t('object', []) :  3 | ['place_of_birth', 'previous_place_of_living', 'bite_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  3 | ['place_of_birth', 'previous_place_of_living', 'bite_type']\n",
      "\t\t('float', [])     :  5 | ['sealed fissure', 'fluorosis', 'sum_hygiene_index', 'right_age', 'sum_hygiene_index last']\n",
      "\t\t('int', [])       : 10 | ['sealed fissure last', 'fluorosis last', 'right_age last', 'not_registered', 'num_caries', ...]\n",
      "\t\t('int', ['bool']) :  2 | ['uncut tooth', 'num_removed_other_reasons']\n",
      "\t0.1s = Fit runtime\n",
      "\t20 features in original data used to generate 20 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 149, Val Rows: 38\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.4474\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.5789\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 8: early stopping\n",
      "\t0.5526\t = Validation score   (accuracy)\n",
      "\t1.86s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.7632\t = Validation score   (accuracy)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.9737\t = Validation score   (accuracy)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7368\t = Validation score   (accuracy)\n",
      "\t1.45s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7105\t = Validation score   (accuracy)\n",
      "\t1.46s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.9211\t = Validation score   (accuracy)\n",
      "\t6.66s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.6053\t = Validation score   (accuracy)\n",
      "\t1.47s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.6053\t = Validation score   (accuracy)\n",
      "\t1.44s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.9474\t = Validation score   (accuracy)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.5526\t = Validation score   (accuracy)\n",
      "\t1.07s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.9737\t = Validation score   (accuracy)\n",
      "\t0.91s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.9737\t = Validation score   (accuracy)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 20.12s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictClass/\")\n"
     ]
    }
   ],
   "source": [
    "save_path = 'agModels-predictClass'  # specifies folder to store trained models\n",
    "\n",
    "predictor = TabularPredictor(label='kpu', path=save_path).fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96824a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=y_test.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0e0359a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kpu</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1101.xlsx</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102.xlsx</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103.xlsx</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104.xlsx</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105.xlsx</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7412.xlsx</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7413.xlsx</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7414.xlsx</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7415.xlsx</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7416.xlsx</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           kpu\n",
       "id            \n",
       "1101.xlsx    9\n",
       "1102.xlsx    6\n",
       "1103.xlsx    6\n",
       "1104.xlsx    9\n",
       "1105.xlsx    3\n",
       "...        ...\n",
       "7412.xlsx    6\n",
       "7413.xlsx    5\n",
       "7414.xlsx    6\n",
       "7415.xlsx    3\n",
       "7416.xlsx    4\n",
       "\n",
       "[191 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2c78bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1101.xlsx    9\n",
       "1102.xlsx    6\n",
       "1103.xlsx    6\n",
       "1104.xlsx    9\n",
       "1105.xlsx    3\n",
       "            ..\n",
       "7412.xlsx    6\n",
       "7413.xlsx    5\n",
       "7414.xlsx    6\n",
       "7415.xlsx    3\n",
       "7416.xlsx    4\n",
       "Name: kpu, Length: 191, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b2175e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TabularPredictor.load(save_path)  # unnecessary, just demonstrates how to load previously-trained predictor from file\n",
    "\n",
    "y_pred = predictor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3ffdc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  \n",
      " id\n",
      "1101.xlsx    7\n",
      "1102.xlsx    6\n",
      "1103.xlsx    6\n",
      "1104.xlsx    9\n",
      "1105.xlsx    2\n",
      "            ..\n",
      "7412.xlsx    6\n",
      "7413.xlsx    4\n",
      "7414.xlsx    2\n",
      "7415.xlsx    0\n",
      "7416.xlsx    4\n",
      "Name: kpu, Length: 191, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions:  \\n\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3637cb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.6596858638743456\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.6596858638743456,\n",
      "    \"balanced_accuracy\": 0.4947778362320405,\n",
      "    \"mcc\": 0.6225067965529583\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "perf = predictor.evaluate_predictions(y_true=y_true, y_pred=y_pred, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74ad33be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
      "0         LightGBMLarge    0.659686   0.973684        0.009459       0.004690   \n",
      "1               XGBoost    0.659686   0.947368        0.012483       0.005871   \n",
      "2              LightGBM    0.659686   0.973684        0.017980       0.004917   \n",
      "3   WeightedEnsemble_L2    0.659686   0.973684        0.022041       0.005327   \n",
      "4      RandomForestGini    0.649215   0.736842        0.169326       0.095991   \n",
      "5      RandomForestEntr    0.643979   0.710526        0.147065       0.098349   \n",
      "6        ExtraTreesEntr    0.623037   0.605263        0.150057       0.094277   \n",
      "7        ExtraTreesGini    0.617801   0.605263        0.165543       0.100993   \n",
      "8              CatBoost    0.602094   0.921053        0.008906       0.005574   \n",
      "9            LightGBMXT    0.602094   0.763158        0.020226       0.006083   \n",
      "10       KNeighborsDist    0.549738   0.578947        0.014961       0.013037   \n",
      "11      NeuralNetFastAI    0.534031   0.552632        0.038095       0.015142   \n",
      "12       KNeighborsUnif    0.513089   0.447368        0.013722       0.009297   \n",
      "13       NeuralNetTorch    0.460733   0.552632        0.018287       0.011873   \n",
      "\n",
      "    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
      "0   0.905413                 0.009459                0.004690   \n",
      "1   0.548491                 0.012483                0.005871   \n",
      "2   0.496633                 0.017980                0.004917   \n",
      "3   0.828353                 0.004061                0.000410   \n",
      "4   1.448607                 0.169326                0.095991   \n",
      "5   1.457044                 0.147065                0.098349   \n",
      "6   1.440788                 0.150057                0.094277   \n",
      "7   1.465642                 0.165543                0.100993   \n",
      "8   6.655922                 0.008906                0.005574   \n",
      "9   0.891447                 0.020226                0.006083   \n",
      "10  0.007174                 0.014961                0.013037   \n",
      "11  1.859909                 0.038095                0.015142   \n",
      "12  0.007299                 0.013722                0.009297   \n",
      "13  1.069669                 0.018287                0.011873   \n",
      "\n",
      "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
      "0            0.905413            1       True         13  \n",
      "1            0.548491            1       True         11  \n",
      "2            0.496633            1       True          5  \n",
      "3            0.331721            2       True         14  \n",
      "4            1.448607            1       True          6  \n",
      "5            1.457044            1       True          7  \n",
      "6            1.440788            1       True         10  \n",
      "7            1.465642            1       True          9  \n",
      "8            6.655922            1       True          8  \n",
      "9            0.891447            1       True          4  \n",
      "10           0.007174            1       True          2  \n",
      "11           1.859909            1       True          3  \n",
      "12           0.007299            1       True          1  \n",
      "13           1.069669            1       True         12  \n"
     ]
    }
   ],
   "source": [
    "print(predictor.leaderboard(x_test_with_kpu, silent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b45d8c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard_hpo = predictor.leaderboard(silent=True)\n",
    "\n",
    "best_model_name = leaderboard_hpo[leaderboard_hpo['stack_level'] == 1]['model'].iloc[0]\n",
    "\n",
    "predictor_info = predictor.info()\n",
    "best_model_info = predictor_info['model_info'][best_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eabd1a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'LightGBMLarge', 'model_type': 'LGBModel', 'problem_type': 'multiclass', 'eval_metric': 'accuracy', 'stopping_metric': 'accuracy', 'fit_time': 0.9054126739501953, 'num_classes': 12, 'quantile_levels': None, 'predict_time': 0.0046901702880859375, 'val_score': 0.9736842105263158, 'hyperparameters': {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3}, 'hyperparameters_fit': {'num_boost_round': 13}, 'hyperparameters_nondefault': ['learning_rate', 'num_leaves', 'feature_fraction', 'min_data_in_leaf'], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None}, 'num_features': 20, 'features': ['sealed fissure', 'uncut tooth', 'fluorosis', 'sum_hygiene_index', 'right_age', 'sealed fissure last', 'fluorosis last', 'sum_hygiene_index last', 'right_age last', 'not_registered', 'num_caries', 'num_filling_caries', 'num_filling_no_caries', 'num_healthy', 'num_removed_caused_by_caries', 'num_removed_other_reasons', 'kpu_last', 'place_of_birth', 'previous_place_of_living', 'bite_type'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x7fb4bf7c7670>, 'memory_size': 627986}\n"
     ]
    }
   ],
   "source": [
    "print(best_model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd4dbfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Hyperparameters (LightGBMLarge):\n"
     ]
    }
   ],
   "source": [
    "print(f'Best Model Hyperparameters ({best_model_name}):')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0175ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3}\n"
     ]
    }
   ],
   "source": [
    "print(best_model_info['hyperparameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dae6bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
